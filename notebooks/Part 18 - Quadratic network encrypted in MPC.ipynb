{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Encryption - Classification and information leakage\n",
    "\n",
    "Our start point is the work on encrypted classification using Function Encryption of the paper [Reading in the Dark: Classifying Encrypted Digits with Functional Encryption](https://eprint.iacr.org/2018/206), and the associated [GitHub repository](https://github.com/edufoursans/reading-in-the-dark).\n",
    "\n",
    "More specifically, the paper provides a new Functional Encryption scheme for quadratic multi-variate polynomials, which can under some hypothesis be seen as a single hidden layer neural network with a quadratic activation.\n",
    "In the paper, the output corresponds to element per class, and it is made in clear. We analyse how this output can disclose information about the initial input or about charasteristics of this input.\n",
    "\n",
    "To this aim, we have just built a dataset which is very similar to MNIST, used in the original paper but which is composed of 26 letter characters of 5 differents fonts. Our goal is two-fold:\n",
    " - Evaluate how the output in clear can be leverage with a public NN to make better prediction than a simple `argmax` function in the character recognition task.\n",
    " - Analyse to what extent the output in clear of the model trained for character recognition can reveal information about the font used, using an \"adversarial\" network.\n",
    " \n",
    "**Purpose**\n",
    "\n",
    "We have studied many aspects of the problem with Functional Encryption, and we are now interested to see how the problem evolves when using Secure Multiparty Computation. As in Part 5, we will be using **fixed precision** tensors. We'll leverage here the PySyft library which provides a way to directly use PyTorch in a fixed precision + securely shared scheme!\n",
    "\n",
    "The setting is completely different: here the protocol is now interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Quadratic model to Additive Sharing Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the precision fractional to 3 as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREC_FRAC = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load torch and syft packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow to load packages from parent\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import syft as sy\n",
    "sy.create_sandbox(globals(), verbose=False, download_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from learn import main, train, test, show_results, show_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the quadratic model that we saved in Part 4! _Be sure that the path and file name match._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadNet(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(QuadNet, self).__init__()\n",
    "        self.proj1 = nn.Linear(784, 50)\n",
    "        self.diag1 = nn.Linear(50, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.proj1(x)\n",
    "        x = x * x\n",
    "        x = self.diag1(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.proj1(x)\n",
    "        x = x * x\n",
    "        x = self.diag1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadNet(\n",
       "  (proj1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (diag1): Linear(in_features=50, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QuadNet(26)\n",
    "path = '../data/models/quad_char.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the model into fixed precision, look how the `diag1.bias` changes for example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0080,  0.0055,  0.0057, -0.0033,  0.0100, -0.0097, -0.0070, -0.0024,\n",
       "         0.0154, -0.0010,  0.0280,  0.0104, -0.0033, -0.0095, -0.0225,  0.0200,\n",
       "         0.0206, -0.0316, -0.0121, -0.0407, -0.0133, -0.0193,  0.0031,  0.0142,\n",
       "         0.0110,  0.0231], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.diag1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadNet(\n",
       "  (proj1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (diag1): Linear(in_features=50, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fix_precision(precision_fractional=PREC_FRAC).share(alice, bob, crypto_provider=jason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4611686018427387903"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = model.diag1.bias.child.field\n",
    "field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdditiveSharingTensor]\n",
       "\t-> (Wrapper)>[PointerTensor | me:16413825280 -> alice:1367676659]\n",
       "\t-> (Wrapper)>[PointerTensor | me:45735775422 -> bob:8298287436]\n",
       "\t*crypto provider: jason*"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.diag1.weight.child.child.child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the components which are necessary for performing an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    \"\"\"Parameters for the testing\"\"\"\n",
    "    def __init__(self):\n",
    "        self.test_batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we load the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 60000 items\n",
      "Testing set  10000 items\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "args = Parser()\n",
    "args.test_batch_size = 10\n",
    "\n",
    "data = learn.load_data()\n",
    "train_data, train_target_char, train_target_family, test_data, test_target_char, test_target_family = data\n",
    "test_target = test_target_char\n",
    "test_dataset = learn.build_tensor_dataset(test_data, test_target)\n",
    "test_loader = utils.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.test_batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the test phase, which in very close to `learn.test`. However, as you see we convert the data into fixed precision, and instead of a full forward pass, we omit the last log_softmax (by using `.transform()`) as it should not be applied in the encryption part so not be applied on the integers. Hence, we apply it after the output is converted back to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc (tmp) 100.0 %\n",
      "1.33 s,  99.72985 % argmax\n",
      "acc (tmp) 85.0 %\n",
      "1.32 s,  99.80278 % argmax\n",
      "acc (tmp) 86.67 %\n",
      "1.31 s,  99.80633 % argmax\n",
      "acc (tmp) 87.5 %\n",
      "1.41 s,  99.8156 % argmax\n",
      "acc (tmp) 90.0 %\n",
      "1.78 s,  99.84619 % argmax\n",
      "acc (tmp) 91.67 %\n",
      "1.47 s,  99.80478 % argmax\n",
      "acc (tmp) 91.43 %\n",
      "1.95 s,  99.43945 % argmax\n",
      "acc (tmp) 91.25 %\n",
      "2.12 s,  99.86865 % argmax\n",
      "acc (tmp) 90.0 %\n",
      "1.37 s,  99.81265 % argmax\n",
      "acc (tmp) 89.0 %\n",
      "1.32 s,  99.79102 % argmax\n",
      "acc (tmp) 90.0 %\n",
      "1.32 s,  99.80792 % argmax\n",
      "acc (tmp) 90.0 %\n",
      "1.31 s,  99.80687 % argmax\n",
      "acc (tmp) 90.0 %\n",
      "1.32 s,  99.79192 % argmax\n",
      "acc (tmp) 90.71 %\n",
      "1.36 s,  99.77653 % argmax\n",
      "acc (tmp) 90.67 %\n",
      "1.35 s,  99.78239 % argmax\n",
      "acc (tmp) 91.25 %\n",
      "1.3 s,  99.80269 % argmax\n",
      "acc (tmp) 91.18 %\n",
      "1.34 s,  99.79688 % argmax\n",
      "acc (tmp) 91.67 %\n",
      "1.35 s,  99.79624 % argmax\n",
      "acc (tmp) 91.05 %\n",
      "1.33 s,  99.80231 % argmax\n",
      "acc (tmp) 91.5 %\n",
      "1.38 s,  99.77153 % argmax\n",
      "acc (tmp) 91.9 %\n",
      "1.34 s,  99.79673 % argmax\n",
      "acc (tmp) 91.36 %\n",
      "1.32 s,  99.78595 % argmax\n",
      "acc (tmp) 91.74 %\n",
      "1.33 s,  99.81126 % argmax\n",
      "acc (tmp) 92.08 %\n",
      "1.39 s,  99.79254 % argmax\n",
      "acc (tmp) 92.4 %\n",
      "1.33 s,  99.81195 % argmax\n",
      "acc (tmp) 92.31 %\n",
      "1.33 s,  99.78522 % argmax\n",
      "acc (tmp) 92.59 %\n",
      "1.33 s,  99.80549 % argmax\n",
      "acc (tmp) 92.86 %\n",
      "1.44 s,  99.81218 % argmax\n",
      "acc (tmp) 92.76 %\n",
      "1.35 s,  99.79347 % argmax\n",
      "acc (tmp) 92.33 %\n",
      "1.36 s,  99.80177 % argmax\n",
      "acc (tmp) 92.58 %\n",
      "1.37 s,  99.7653 % argmax\n",
      "acc (tmp) 92.81 %\n",
      "1.35 s,  99.79755 % argmax\n",
      "acc (tmp) 92.73 %\n",
      "1.43 s,  99.80567 % argmax\n",
      "acc (tmp) 92.94 %\n",
      "1.35 s,  99.71234 % argmax\n",
      "acc (tmp) 92.86 %\n",
      "1.35 s,  99.79778 % argmax\n",
      "acc (tmp) 92.78 %\n",
      "1.38 s,  99.78602 % argmax\n",
      "acc (tmp) 92.97 %\n",
      "1.42 s,  99.79904 % argmax\n",
      "acc (tmp) 92.37 %\n",
      "1.44 s,  99.79662 % argmax\n",
      "acc (tmp) 92.31 %\n",
      "1.46 s,  99.79948 % argmax\n",
      "acc (tmp) 92.5 %\n",
      "1.43 s,  99.77591 % argmax\n",
      "acc (tmp) 92.68 %\n",
      "1.4 s,  99.81151 % argmax\n",
      "acc (tmp) 92.62 %\n",
      "1.44 s,  99.79771 % argmax\n",
      "acc (tmp) 92.56 %\n",
      "1.35 s,  99.80519 % argmax\n",
      "acc (tmp) 92.73 %\n",
      "1.48 s,  99.79052 % argmax\n",
      "acc (tmp) 92.89 %\n",
      "1.45 s,  99.79908 % argmax\n",
      "acc (tmp) 93.04 %\n",
      "1.35 s,  99.80485 % argmax\n",
      "acc (tmp) 92.98 %\n",
      "1.42 s,  99.80984 % argmax\n",
      "acc (tmp) 93.12 %\n",
      "1.38 s,  99.80144 % argmax\n",
      "acc (tmp) 93.27 %\n",
      "1.37 s,  99.7801 % argmax\n",
      "acc (tmp) 93.4 %\n",
      "1.45 s,  99.77861 % argmax\n",
      "acc (tmp) 93.53 %\n",
      "1.41 s,  99.81812 % argmax\n",
      "acc (tmp) 93.65 %\n",
      "1.35 s,  99.78966 % argmax\n",
      "acc (tmp) 93.58 %\n",
      "1.4 s,  99.8153 % argmax\n",
      "acc (tmp) 93.7 %\n",
      "1.43 s,  99.79511 % argmax\n",
      "acc (tmp) 93.82 %\n",
      "1.53 s,  99.80784 % argmax\n",
      "acc (tmp) 93.75 %\n",
      "1.43 s,  99.79509 % argmax\n",
      "acc (tmp) 93.86 %\n",
      "1.45 s,  99.79911 % argmax\n",
      "acc (tmp) 93.97 %\n",
      "1.46 s,  99.80942 % argmax\n",
      "acc (tmp) 93.9 %\n",
      "1.51 s,  99.81589 % argmax\n",
      "acc (tmp) 94.0 %\n",
      "1.45 s,  99.7925 % argmax\n",
      "acc (tmp) 94.1 %\n",
      "1.42 s,  99.81445 % argmax\n",
      "acc (tmp) 93.87 %\n",
      "1.33 s,  99.79281 % argmax\n",
      "acc (tmp) 93.97 %\n",
      "1.38 s,  99.80846 % argmax\n",
      "acc (tmp) 94.06 %\n",
      "1.32 s,  99.76913 % argmax\n",
      "acc (tmp) 94.15 %\n",
      "1.46 s,  99.82105 % argmax\n",
      "acc (tmp) 94.24 %\n",
      "1.46 s,  99.81558 % argmax\n",
      "acc (tmp) 94.18 %\n",
      "1.39 s,  99.78862 % argmax\n",
      "acc (tmp) 94.26 %\n",
      "1.34 s,  99.79493 % argmax\n",
      "acc (tmp) 94.2 %\n",
      "1.31 s,  99.79814 % argmax\n",
      "acc (tmp) 94.29 %\n",
      "1.32 s,  99.80472 % argmax\n",
      "acc (tmp) 94.37 %\n",
      "1.31 s,  99.79803 % argmax\n",
      "acc (tmp) 94.31 %\n",
      "1.34 s,  99.80728 % argmax\n",
      "acc (tmp) 94.11 %\n",
      "1.33 s,  99.8064 % argmax\n",
      "acc (tmp) 94.05 %\n",
      "1.39 s,  99.80603 % argmax\n",
      "acc (tmp) 94.13 %\n",
      "1.39 s,  99.78266 % argmax\n",
      "acc (tmp) 94.08 %\n",
      "1.44 s,  99.80462 % argmax\n",
      "acc (tmp) 93.9 %\n",
      "1.33 s,  99.80678 % argmax\n",
      "acc (tmp) 93.85 %\n",
      "1.29 s,  99.79082 % argmax\n",
      "acc (tmp) 93.92 %\n",
      "1.3 s,  99.78313 % argmax\n",
      "acc (tmp) 94.0 %\n",
      "1.3 s,  99.7977 % argmax\n",
      "acc (tmp) 94.07 %\n",
      "1.3 s,  99.80126 % argmax\n",
      "acc (tmp) 94.15 %\n",
      "1.3 s,  99.80248 % argmax\n",
      "acc (tmp) 94.1 %\n",
      "1.28 s,  99.79399 % argmax\n",
      "acc (tmp) 94.17 %\n",
      "1.3 s,  99.80336 % argmax\n",
      "acc (tmp) 94.12 %\n",
      "1.31 s,  99.80411 % argmax\n",
      "acc (tmp) 94.07 %\n",
      "1.29 s,  99.80157 % argmax\n",
      "acc (tmp) 94.02 %\n",
      "1.29 s,  99.8009 % argmax\n",
      "acc (tmp) 94.09 %\n",
      "1.28 s,  99.79952 % argmax\n",
      "acc (tmp) 94.04 %\n",
      "1.28 s,  99.79171 % argmax\n",
      "acc (tmp) 94.11 %\n",
      "1.31 s,  99.80689 % argmax\n",
      "acc (tmp) 94.18 %\n",
      "1.29 s,  99.79895 % argmax\n",
      "acc (tmp) 94.13 %\n",
      "1.29 s,  99.80357 % argmax\n",
      "acc (tmp) 94.19 %\n",
      "1.28 s,  99.79745 % argmax\n",
      "acc (tmp) 94.26 %\n",
      "1.3 s,  99.80088 % argmax\n",
      "acc (tmp) 94.32 %\n",
      "1.28 s,  99.78517 % argmax\n",
      "acc (tmp) 94.38 %\n",
      "1.3 s,  99.8023 % argmax\n",
      "acc (tmp) 94.33 %\n",
      "1.29 s,  99.7996 % argmax\n",
      "acc (tmp) 94.39 %\n",
      "1.28 s,  99.79916 % argmax\n",
      "acc (tmp) 94.44 %\n",
      "1.28 s,  99.80158 % argmax\n",
      "acc (tmp) 94.4 %\n",
      "1.3 s,  99.79961 % argmax\n",
      "acc (tmp) 94.46 %\n",
      "1.29 s,  99.80541 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.28 s,  99.79478 % argmax\n",
      "acc (tmp) 94.47 %\n",
      "1.29 s,  99.77922 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.28 s,  99.79926 % argmax\n",
      "acc (tmp) 94.38 %\n",
      "1.28 s,  99.80026 % argmax\n",
      "acc (tmp) 94.43 %\n",
      "1.28 s,  99.80544 % argmax\n",
      "acc (tmp) 94.39 %\n",
      "1.29 s,  99.80037 % argmax\n",
      "acc (tmp) 94.35 %\n",
      "1.29 s,  99.80268 % argmax\n",
      "acc (tmp) 94.4 %\n",
      "1.28 s,  99.75566 % argmax\n",
      "acc (tmp) 94.45 %\n",
      "1.29 s,  99.78988 % argmax\n",
      "acc (tmp) 94.41 %\n",
      "1.29 s,  99.80075 % argmax\n",
      "acc (tmp) 94.46 %\n",
      "1.29 s,  99.80227 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.28 s,  99.7975 % argmax\n",
      "acc (tmp) 94.47 %\n",
      "1.29 s,  99.79874 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.28 s,  99.79943 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.28 s,  99.79579 % argmax\n",
      "acc (tmp) 94.62 %\n",
      "1.29 s,  99.79299 % argmax\n",
      "acc (tmp) 94.66 %\n",
      "1.3 s,  99.78941 % argmax\n",
      "acc (tmp) 94.62 %\n",
      "1.28 s,  99.80298 % argmax\n",
      "acc (tmp) 94.67 %\n",
      "1.29 s,  99.80364 % argmax\n",
      "acc (tmp) 94.63 %\n",
      "1.28 s,  99.79179 % argmax\n",
      "acc (tmp) 94.67 %\n",
      "1.32 s,  99.8002 % argmax\n",
      "acc (tmp) 94.63 %\n",
      "1.29 s,  99.79805 % argmax\n",
      "acc (tmp) 94.6 %\n",
      "1.3 s,  99.80191 % argmax\n",
      "acc (tmp) 94.56 %\n",
      "1.29 s,  99.79622 % argmax\n",
      "acc (tmp) 94.6 %\n",
      "1.29 s,  99.79659 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.29 s,  99.80636 % argmax\n",
      "acc (tmp) 94.61 %\n",
      "1.29 s,  99.78996 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.29 s,  99.79603 % argmax\n",
      "acc (tmp) 94.62 %\n",
      "1.29 s,  99.79673 % argmax\n",
      "acc (tmp) 94.58 %\n",
      "1.3 s,  99.80688 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.29 s,  99.80564 % argmax\n",
      "acc (tmp) 94.59 %\n",
      "1.29 s,  99.80033 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.28 s,  99.80486 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.29 s,  99.79162 % argmax\n",
      "acc (tmp) 94.56 %\n",
      "1.31 s,  99.80557 % argmax\n",
      "acc (tmp) 94.53 %\n",
      "1.29 s,  99.79238 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.29 s,  99.80535 % argmax\n",
      "acc (tmp) 94.6 %\n",
      "1.3 s,  99.78978 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.3 s,  99.80487 % argmax\n",
      "acc (tmp) 94.54 %\n",
      "1.3 s,  99.80103 % argmax\n",
      "acc (tmp) 94.58 %\n",
      "1.29 s,  99.77075 % argmax\n",
      "acc (tmp) 94.62 %\n",
      "1.29 s,  99.79971 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.3 s,  99.80361 % argmax\n",
      "acc (tmp) 94.48 %\n",
      "1.29 s,  99.79531 % argmax\n",
      "acc (tmp) 94.38 %\n",
      "1.3 s,  99.78215 % argmax\n",
      "acc (tmp) 94.35 %\n",
      "1.3 s,  99.80164 % argmax\n",
      "acc (tmp) 94.32 %\n",
      "1.32 s,  99.80492 % argmax\n",
      "acc (tmp) 94.3 %\n",
      "1.31 s,  99.79031 % argmax\n",
      "acc (tmp) 94.33 %\n",
      "1.3 s,  99.79936 % argmax\n",
      "acc (tmp) 94.37 %\n",
      "1.29 s,  99.80025 % argmax\n",
      "acc (tmp) 94.41 %\n",
      "1.3 s,  99.80061 % argmax\n",
      "acc (tmp) 94.44 %\n",
      "1.29 s,  99.80027 % argmax\n",
      "acc (tmp) 94.48 %\n",
      "1.29 s,  99.7939 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.29 s,  99.80325 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.29 s,  99.8068 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.3 s,  99.79807 % argmax\n",
      "acc (tmp) 94.49 %\n",
      "1.28 s,  99.801 % argmax\n",
      "acc (tmp) 94.47 %\n",
      "1.3 s,  99.80105 % argmax\n",
      "acc (tmp) 94.44 %\n",
      "1.3 s,  99.80091 % argmax\n",
      "acc (tmp) 94.47 %\n",
      "1.3 s,  99.77385 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.29 s,  99.80098 % argmax\n",
      "acc (tmp) 94.54 %\n",
      "1.28 s,  99.798 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.3 s,  99.80648 % argmax\n",
      "acc (tmp) 94.61 %\n",
      "1.29 s,  99.78447 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.29 s,  99.79972 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.3 s,  99.79571 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.3 s,  99.80312 % argmax\n",
      "acc (tmp) 94.5 %\n",
      "1.3 s,  99.75782 % argmax\n",
      "acc (tmp) 94.47 %\n",
      "1.29 s,  99.80552 % argmax\n",
      "acc (tmp) 94.5 %\n",
      "1.29 s,  99.79513 % argmax\n",
      "acc (tmp) 94.48 %\n",
      "1.29 s,  99.80108 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.29 s,  99.79993 % argmax\n",
      "acc (tmp) 94.54 %\n",
      "1.29 s,  99.80143 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.3 s,  99.80305 % argmax\n",
      "acc (tmp) 94.49 %\n",
      "1.29 s,  99.80133 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.29 s,  99.79045 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.3 s,  99.78971 % argmax\n",
      "acc (tmp) 94.58 %\n",
      "1.29 s,  99.80416 % argmax\n",
      "acc (tmp) 94.61 %\n",
      "1.29 s,  99.80299 % argmax\n",
      "acc (tmp) 94.64 %\n",
      "1.28 s,  99.80435 % argmax\n",
      "acc (tmp) 94.56 %\n",
      "1.27 s,  99.80217 % argmax\n",
      "acc (tmp) 94.59 %\n",
      "1.29 s,  99.79503 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.28 s,  99.79943 % argmax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc (tmp) 94.54 %\n",
      "1.28 s,  99.80213 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.29 s,  99.79749 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.29 s,  99.80557 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.28 s,  99.79333 % argmax\n",
      "acc (tmp) 94.5 %\n",
      "1.28 s,  99.7929 % argmax\n",
      "acc (tmp) 94.53 %\n",
      "1.28 s,  99.80113 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.29 s,  99.80531 % argmax\n",
      "acc (tmp) 94.58 %\n",
      "1.29 s,  99.79959 % argmax\n",
      "acc (tmp) 94.56 %\n",
      "1.28 s,  99.80439 % argmax\n",
      "acc (tmp) 94.54 %\n",
      "1.28 s,  99.78926 % argmax\n",
      "acc (tmp) 94.51 %\n",
      "1.29 s,  99.79283 % argmax\n",
      "acc (tmp) 94.54 %\n",
      "1.28 s,  99.78396 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.28 s,  99.79352 % argmax\n",
      "acc (tmp) 94.49 %\n",
      "1.29 s,  99.80105 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.28 s,  99.79664 % argmax\n",
      "acc (tmp) 94.5 %\n",
      "1.28 s,  99.79601 % argmax\n",
      "acc (tmp) 94.53 %\n",
      "1.28 s,  99.75377 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.28 s,  99.76932 % argmax\n",
      "acc (tmp) 94.58 %\n",
      "1.28 s,  99.79941 % argmax\n",
      "acc (tmp) 94.61 %\n",
      "1.28 s,  99.80052 % argmax\n",
      "acc (tmp) 94.54 %\n",
      "1.32 s,  99.80042 % argmax\n",
      "acc (tmp) 94.56 %\n",
      "1.28 s,  99.80051 % argmax\n",
      "acc (tmp) 94.54 %\n",
      "1.28 s,  99.78884 % argmax\n",
      "acc (tmp) 94.52 %\n",
      "1.28 s,  99.73813 % argmax\n",
      "acc (tmp) 94.55 %\n",
      "1.28 s,  99.74953 % argmax\n",
      "acc (tmp) 94.57 %\n",
      "1.28 s,  99.80114 % argmax\n",
      "acc (tmp) 94.6 %\n",
      "1.27 s,  99.79737 % argmax\n",
      "acc (tmp) 94.62 %\n",
      "1.28 s,  99.79958 % argmax\n",
      "acc (tmp) 94.65 %\n",
      "1.28 s,  99.80572 % argmax\n",
      "acc (tmp) 94.58 %\n",
      "1.29 s,  99.79452 % argmax\n",
      "acc (tmp) 94.6 %\n",
      "1.28 s,  99.79738 % argmax\n",
      "acc (tmp) 94.58 %\n",
      "1.28 s,  99.78951 % argmax\n",
      "acc (tmp) 94.61 %\n",
      "1.29 s,  99.78916 % argmax\n",
      "acc (tmp) 94.63 %\n",
      "1.28 s,  99.80084 % argmax\n",
      "acc (tmp) 94.61 %\n",
      "1.27 s,  99.79756 % argmax\n",
      "acc (tmp) 94.5 %\n",
      "1.4 s,  99.81306 % argmax\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-60c920323a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPREC_FRAC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-60c920323a9a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader, prec_frac)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <-- Not calling forward to avoid the log_softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mforward_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0margmax_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <-- This is new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_syft_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             indices = (\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mfix_prec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrypto_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrypto_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mmax_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36m__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36mge\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ge__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36mpositive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/crypto/securenn.py\u001b[0m in \u001b[0;36mrelu_deriv\u001b[0;34m(a_sh)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/crypto/securenn.py\u001b[0m in \u001b[0;36mmsb\u001b[0;34m(a_sh, alice, bob)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# 9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \"\"\"Multiplies two number for details see mul\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_public_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_private_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36m_private_mul\u001b[0;34m(self, other, equation)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For multiplication a cryto_provider must be passed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mshares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspdz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspdz_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrypto_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mshares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/crypto/spdz.py\u001b[0m in \u001b[0;36mspdz_mul\u001b[0;34m(cmd, x_sh, y_sh, crypto_provider, field)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Reconstruct and send to all workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mdelta_epsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, inplace, *location)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             output = syft.frameworks.torch.tensors.interpreters.MultiPointerTensor(\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, inplace, *location)\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgarbage_collect_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, tensor, workers, ptr_id)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m# Send the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend_obj\u001b[0;34m(self, obj, location)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mreceive\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \"\"\"\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Step 1: serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mbin_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj, simplified)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# which the fast serializer cannot handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msimplified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0msimple_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_simplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0msimple_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde.py\u001b[0m in \u001b[0;36m_simplify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mcurrent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde.py\u001b[0m in \u001b[0;36m_simplify_collection\u001b[0;34m(my_collection)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# Step 1: serialize each part of the collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_collection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mpieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_simplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;31m# Step 2: convert back to original type and return serialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde.py\u001b[0m in \u001b[0;36m_simplify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mcurrent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde.py\u001b[0m in \u001b[0;36m_simplify_torch_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \"\"\"\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mtensor_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_serialize_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# note we need to do this expicitly because torch.save does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde.py\u001b[0m in \u001b[0;36m_serialize_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_tensor_serializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde.py\u001b[0m in \u001b[0;36mtorch_tensor_serializer\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;34m\"\"\"Strategy to serialize a tensor using Torch saver\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mbinary_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/env/pysyft/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/env/pysyft/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/env/pysyft/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, prec_frac):\n",
    "    test_loss = -1\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            start_time = time.time()\n",
    "            data.fix_precision_(precision_fractional=prec_frac).share_(alice, bob, crypto_provider=jason) # <-- This is new\n",
    "            output = model.transform(data) # <-- Not calling forward to avoid the log_softmax\n",
    "            forward_time = time.time()\n",
    "            pred = output.argmax(dim=1)\n",
    "            argmax_time = time.time()\n",
    "            pred = pred.get().float_precision().long() # <-- This is new\n",
    "            #pred = output.argmax(1, keepdim=True)  # get the index of the max log-probability\n",
    "            total_time = time.time()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += args.test_batch_size\n",
    "            print('acc (tmp)', round(100.*correct/total, 2), '%')\n",
    "            total_duration = total_time-start_time\n",
    "            print(\n",
    "                round(total_duration/args.test_batch_size, 2), \"s, \", \n",
    "                round(100*(argmax_time-forward_time)/total_duration, 5), \"% argmax\"\n",
    "            )\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), acc))\n",
    "    \n",
    "    return acc\n",
    "\n",
    "test(model, test_loader, PREC_FRAC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As you observe, the model behave properly as we achieve the same accuracy (at 94.6%). However, the argmax function computed privately is still very slow and makes a complete evaluation of the testing set unpractical. The time per sample is approximately of 1.3 seconds, which is a bit less than FE (Article [Reading in the dark](https://eprint.iacr.org/2018/206.pdf) reports a 4.8s delay in comparison, but for a 10 class output. The security settings can't be compared as the MPC is provided in an honest but curious setting and relies on information theoretic security. Transforming the MPC implementation with higher security standard would probably lead to an important overhead (use of zero knowledge, etc). In return, FE leaks critical information as all this project demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
