{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Encryption - Classification and information leakage\n",
    "\n",
    "We have seen how to improve the character recognition by replacing the argmax at the output of the private network with additional layers. We are now interested in finding if we can use the output of the private network to improve the font recognition. To do this, we first train the private network on the digit recognition task. We then freeze the private layers and replace the argmax with new layers which form what we call the collateral model and which try to predict the font.\n",
    "\n",
    "As there are only two fonts, a perfectly blind network should have 50% accuracy in the font recognition task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Collateral Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the code directly from the repo, to make the notebook more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow to load packages from parent\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import learn\n",
    "from learn import main, train, test, show_results, show_confusion_matrix\n",
    "from learn.models import QuadNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Loading the quadratic baseline\n",
    "Let's train the baseline model and this how we can use its output to train a collateral network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CHAR = 10\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 20\n",
    "        self.lr = 0.0006\n",
    "        self.momentum = 0.5\n",
    "        self.test_batch_size = 1000\n",
    "        self.batch_size = 64\n",
    "        self.log_interval = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 60000 items\n",
      "Testing set  10000 items\n",
      "Learning on char \n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.332097\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.189784\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.105172\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.077282\n",
      "\n",
      "Test set: Average loss: 0.0874, Accuracy: 9747/10000 (97.47%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.066652\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.067274\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.055420\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.015269\n",
      "\n",
      "Test set: Average loss: 0.0636, Accuracy: 9825/10000 (98.25%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.033876\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.098051\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.001078\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.002234\n",
      "\n",
      "Test set: Average loss: 0.0443, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.008741\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.011260\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.006401\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.004734\n",
      "\n",
      "Test set: Average loss: 0.0404, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.011643\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.002169\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.012894\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.015012\n",
      "\n",
      "Test set: Average loss: 0.0409, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.004021\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.008985\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.010705\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.001548\n",
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.005876\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.005995\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001665\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.000143\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 9922/10000 (99.22%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.004140\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000102\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.005202\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000672\n",
      "\n",
      "Test set: Average loss: 0.0365, Accuracy: 9906/10000 (99.06%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000095\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000573\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001242\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000710\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000897\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000237\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000130\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.000507\n",
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9926/10000 (99.26%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000122\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.000587\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.000583\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.000376\n",
      "\n",
      "Test set: Average loss: 0.0319, Accuracy: 9926/10000 (99.26%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000473\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.000445\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.000679\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.000461\n",
      "\n",
      "Test set: Average loss: 0.0322, Accuracy: 9929/10000 (99.29%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000080\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.000435\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.000165\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.000192\n",
      "\n",
      "Test set: Average loss: 0.0322, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000677\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.000530\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000675\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.000566\n",
      "\n",
      "Test set: Average loss: 0.0324, Accuracy: 9932/10000 (99.32%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000144\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.000102\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.000788\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.000142\n",
      "\n",
      "Test set: Average loss: 0.0326, Accuracy: 9932/10000 (99.32%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000136\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.000414\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.000192\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.000247\n",
      "\n",
      "Test set: Average loss: 0.0329, Accuracy: 9928/10000 (99.28%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.000475\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.000281\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.000263\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.000558\n",
      "\n",
      "Test set: Average loss: 0.0328, Accuracy: 9931/10000 (99.31%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000490\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.000146\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.000056\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.000138\n",
      "\n",
      "Test set: Average loss: 0.0326, Accuracy: 9931/10000 (99.31%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.000105\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.000334\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.000191\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.000136\n",
      "\n",
      "Test set: Average loss: 0.0332, Accuracy: 9932/10000 (99.32%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.000041\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.000213\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.000084\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.000392\n",
      "\n",
      "Test set: Average loss: 0.0332, Accuracy: 9932/10000 (99.32%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "quad_model = QuadNet(N_CHAR)\n",
    "optimizer = optim.Adam(quad_model.parameters(), lr=self.lr)\n",
    "args = Parser()\n",
    "results['QuadNet'], model, pred_labels = main(\n",
    "    model=quad_model,\n",
    "    args=args,\n",
    "    optimizer=optimizer,\n",
    "    model_type='quad',\n",
    "    task='char',\n",
    "    return_model=True,\n",
    "    return_pred_label=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model so that we won't have to train it again. _Make sure have the correct path and directories._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../data/models/quad_char.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Setting up the collaterak task\n",
    "\n",
    "We will now use the output of the trained baseline model which is freezed as an input of another model called the `collateral_model` which will try to predict on another task, namely the family recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are little change compared to the usual test, train and main functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_train(args, adversarial_model, model, train_loader, adv_optimizer, epoch):\n",
    "    adversarial_model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = model.transform(data)  # <-- This is new\n",
    "        adv_optimizer.zero_grad()\n",
    "        output = adversarial_model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        adv_optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def adversarial_test(args, adversarial_model, model, test_loader):\n",
    "    adversarial_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    pred_labels = None\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = model.transform(data) # <-- This is new: like the forward but without the log softmax\n",
    "            output = adversarial_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            pred_labels_batch = torch.stack((pred, target.view_as(pred))).view(2, args.test_batch_size)\n",
    "            if pred_labels is None:\n",
    "                pred_labels = pred_labels_batch\n",
    "            else:\n",
    "                pred_labels = torch.cat((pred_labels, pred_labels_batch), dim=1).view(2, -1)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), acc))\n",
    "    \n",
    "    return acc, pred_labels.transpose(0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the collateral model that we will use. We use the same CNN structure as seen previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateralCNN(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(CollateralCNN, self).__init__()\n",
    "        self.lin1 = nn.Linear(N_CHAR, 784)\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.seed = 1\n",
    "        self.test_batch_size = 1000\n",
    "        self.batch_size = 64\n",
    "        self.log_interval = 300\n",
    "        \n",
    "def build_tensor_dataset(data, target):\n",
    "    normed_data = [(d - d.mean()) / d.std() for d in data]\n",
    "    normed_data = torch.stack([torch.Tensor(d).reshape(1, 28, 28) for d in normed_data])\n",
    "    target = torch.LongTensor([i[0] for i in target])\n",
    "    tensor_dataset = utils.TensorDataset(normed_data, target)\n",
    "    return tensor_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base quadratic model is already trained to detect char, which it does not to badly.\n",
    "We compute explicitely the weight sum of the quadratic model parameters to verify that this private model is left unchanged after the collateral learning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.9486, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_param_norm = quad_model.proj1.weight.norm() + quad_model.diag1.weight.norm()\n",
    "quad_param_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We new try to detect using its output, the family of the original input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 60000 items\n",
      "Testing set  10000 items\n"
     ]
    }
   ],
   "source": [
    "data = learn.load_data()\n",
    "train_data, train_target_char, train_target_family, test_data, test_target_char, test_target_family = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collateral_phase(model):\n",
    "    args = Parser()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    # setting = the family recognition task\n",
    "    train_dataset = build_tensor_dataset(train_data, train_target_family)\n",
    "    test_dataset = build_tensor_dataset(test_data, test_target_family)\n",
    "    \n",
    "    train_loader = utils.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size, shuffle=True\n",
    "    )\n",
    "    \n",
    "    test_loader = utils.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=args.test_batch_size, shuffle=True\n",
    "    )\n",
    "    \n",
    "    adversarial_model = CollateralCNN(output_size=N_CHAR)\n",
    "    adversarial_optimizer = optim.SGD(adversarial_model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    \n",
    "    test_perfs = []\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        adversarial_train(args, adversarial_model, model, train_loader, adversarial_optimizer, epoch)\n",
    "        acc, pred_labels = adversarial_test(args, adversarial_model, model, test_loader)\n",
    "        test_perfs.append(acc)\n",
    "        \n",
    "    return test_perfs, pred_labels\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 3.379620\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.108436\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.353031\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.093687\n",
      "\n",
      "Test set: Average loss: 0.2377, Accuracy: 9000/10000 (90.00%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.206386\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.366531\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.403316\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.114806\n",
      "\n",
      "Test set: Average loss: 0.2051, Accuracy: 9167/10000 (91.67%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.207643\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.211668\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.160555\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.196850\n",
      "\n",
      "Test set: Average loss: 0.2123, Accuracy: 9114/10000 (91.14%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.323305\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.167466\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.124736\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.114201\n",
      "\n",
      "Test set: Average loss: 0.1865, Accuracy: 9257/10000 (92.57%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.131490\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.200057\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.129180\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.227526\n",
      "\n",
      "Test set: Average loss: 0.1735, Accuracy: 9269/10000 (92.69%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.164158\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.297443\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.086167\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.093539\n",
      "\n",
      "Test set: Average loss: 0.1812, Accuracy: 9242/10000 (92.42%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.344726\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.139630\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.109765\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.263628\n",
      "\n",
      "Test set: Average loss: 0.1608, Accuracy: 9350/10000 (93.50%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.179664\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.075012\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.178188\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.066143\n",
      "\n",
      "Test set: Average loss: 0.1659, Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.166795\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.054752\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.126306\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.085038\n",
      "\n",
      "Test set: Average loss: 0.1620, Accuracy: 9343/10000 (93.43%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.111195\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.180790\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.044817\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.205811\n",
      "\n",
      "Test set: Average loss: 0.1721, Accuracy: 9332/10000 (93.32%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_perfs, pred_labels = collateral_phase(quad_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results({'Collateral model': test_perfs}, title=\"Learning curve for the collateral model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "First, let's verify that the private model weights have not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert quad_param_norm == quad_model.proj1.weight.norm() + quad_model.diag1.weight.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, one could ask the difference with the setting where we put a CNN (the same) on top of the private network to learn font family recognition in Part 2. The major difference is that in Part 2 we could modify the private network weights, while here we couldn't, and moreover its weights were optimised to perform a completely different task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, as this experiment shows, the prediction accuracy of the model is embarrassingly good! This shows that the information contained in the 10 neurons output is far more important than just information about characters. In particular, we can infer quite precisely information about the font of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment proves the information leakage in the public output on which we publicly apply the argmax, as we are able the distinguish the font with over 93%.\n",
    "\n",
    "Note however that this is less than the 98.5% we had in Part 2. In addition, recall that what we do here has no impoact on the main task accuracy.\n",
    "\n",
    "We will now use the technique seen in Part 2 to also add extra layers on the main task. We will see how this affects the collateral accuracy and this will allow to adjust a new hyper-parameter: the size of the private output of the quadratic model. Our intuition is that reducing this parameter means less information is leaked and therefore the collateral learning is harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### If you like it, star it!\n",
    "\n",
    "The easiest way to show support is just by starring the Repos! This helps raise awareness on this topics and is a precious feedback for the repo maintainers!\n",
    "\n",
    "- [Star the Repo](https://github.com/LaRiffle/collateral-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
